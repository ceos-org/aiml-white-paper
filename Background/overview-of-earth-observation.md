## 2.1. Overview of Earth Observation[^3]

**Observation** is the process through which mankind is able to collect factual data about their physical surroundings. While **Earth Observation** per se comprises any observation that targets the Earth and anything in on or around it, the most prominent of its sub-domains is probably ‘remote sensing’, of which a significant part is carried out using satellites.  Satellite EO can be thought of as a modern day [‘macroscope’](https://en.wikipedia.org/wiki/Macroscope_\(science_concept\)). Whilst traditional microscopes enabled us to study our world at the micro scale, satellite EO is enabling a global-scale view of the Earth and its processes.  
   
The term **remote sensing** refers to the fact that we can observe properties of phenomena from a larger distance usually without any mechanical connection or interaction. It is useful to distinguish this type of observation from those done at smaller, for the observation negligible, distance, which often are referred to as **in-situ**. Any observation requires a signal to carry information about a phenomenon to the sensor. If mechanical interaction (such as in seismics and sonar, which might validly be called remote sensing as well) is neglected here, only two types of signal carriers remain, gravitational and electromagnetic fields.  The by far most used type of signals in remote sensing on which we are hence focussing, are **electromagnetic (EM) waves**.  
   
Electromagnetic waves have an almost unlimited range of wavelengths, called the **Electromagnetic Spectrum** , stretching from atomic to galactic dimensions, part of which is shown in **Figure 2.1-1**. Depending on their wavelength they interact with physical phenomena such as matter at very different scales. Of practical use in remote sensing are wavelengths ranging from some tenth of a micrometre (10\-6m) revealing molecular structure and micro-particles, up to several meters reacting to macroscopic properties like object’s surface roughness or dielectric properties (water content).

 ![Electromagnetic spectrum as measured in micrometers](/figures/Figure2.1-1.png)
**Figure 2.1-1**: Electromagnetic spectrum as measured in micrometers. Visible wavelengths (lower bar) are in nanometres. Passive optical satellite instruments measure light in the Visible to Infrared parts which arrives either as reflected sun-light or thermally emitted. In contrast, Synthetic Aperture Radar satellites are active , they generate and detect their own signal in the Microwave region. Source : [CTAHR](https://www.ctahr.hawaii.edu/miuralab/projects/makaha/intro_rs.html). 


**Sensors** are key elements of any observation, as they record the signal and  transform it into data. Each sensor thereby inherently takes a ‘snapshot’ of the observed target, which is a **sample** in space, wavelength (spectral or other signal), and time. There is no generally acknowledged **taxonomy of EO sensors** or techniques, but several attributes can be combined to distinguish the most important types in which sensors observe (or sample) phenomena across these dimensions.  
   
In the **spatial dimension** sensors can measure just a single sample, generate 1D coherent profiles, or 2D coherent rasters, being labelled as sounders, profilers, or imagers respectively. Of primary interest to the user is of course the spatial size of the individual sample, also called ‘pixel’. The measured sample size is closely related to the capacity of the sensor to picture the target with a certain detail, often referred to as **spatial resolution**. Spatial resolution is mostly expressed in meters as the size of the pixels which in most cases is roughly identical to their distance.  
   
In EO spatial resolution can range from centimeters to kilometers and is often divided into classes from ‘very high’ (VHR), to ‘high’ (HR), ‘moderate’ (MR), and ’low’ (LR) without internationally applied norms. A relatively detailed and widely used resolution scale is the one used in the Copernicus programme, displayed in **Figure 2.1-2.**  
   
 ![A common scale to categorise the spatial resolution of EO sensors in the range from below 1m to beyond 300m](/figures/Figure2.1-2.png)  
**Figure 2.1-2**: A common scale to categorise the spatial resolution of EO sensors in the range from below 1m to beyond 300m. Source: [ESA](https://www.esa.int/ESA_Multimedia/Images/2021/09/Data_resolution_classes_within_the_Copernicus_programme).  
   
Equally important is the **spectral dimension**, i.e. which part of the electromagnetic spectrum, often called **band** or **channel**, a sensor is sampling and whether it works only with a single band or multiple such bands. Especially in the optical range most sensors are not working with just a single band (‘monospectral’ or ‘monochromatic’), but with a multitude of bands according to which they are called either **multispectral** (‘multiband’) for a few to tens of bands or **hyperspectral** if the number of bands exceeds roughly a hundred. If the bands are spectrally continuous one would also speak of a **(imaging) spectrometer**. The width and distance of the individual spectral band passes also determines the **spectral resolution** of the sensor.  
   
Another primary characteristic of a sensor is whether it just registers a signal received from the target, then called **passive** sensing, or whether it emits that signal to register the response after interaction with the target, defining **active** sensing.  
   
Finally, in the **temporal dimension**, as most observations need to be done repeatedly, the attribute used to characterise sampling is **revisit time,** **repeat frequency,** or **cadence**. If the sensor is mounted on a satellite revisit time is usually very regular and often done such that the local (solar) time of the observation is the same on different days (**sun-synchronous**) in order to maintain observation and target conditions which have diurnal cycles.

The relationship between the spatial resolution and the temporal resolution is plotted for selected satellite missions in Figure 2.1-3.

![Revisit period vs. spatial resolution of selected optical and SAR satellite missions](/figures/Figure2.1-3.png)  
**Figure 2.1-3**: Revisit period vs. spatial resolution of selected optical and SAR satellite missions.  Source: [Kalatzis et al. (2022)](https://sa.catapult.org.uk/digital-library/white-paper-state-of-ai-for-earth-observation/)  © Satellite Applications Catapult. 

   
For AI/ML applications in Earth Observation, it is of paramount importance to understand that most of the desired environmental information cannot be **directly** assessed by EO sensors, which depend primarily on electromagnetic signals. However, spectral, spatial, and temporal variations in these signals contain a wealth of **indirect** information. This can be extracted if there is a physical link between the observed signal and the target variable — such as the relationship between photosynthesis and its characteristic light absorption.  
These links can be exploited using **physical (parametric)** models, which require a detailed understanding of the underlying phenomena, or through **non-parametric, often stochastic** methods such as AI/ML, which rely on sufficient training or reference data. However, the ability to infer information is inherently limited when the desired variable is not — or not reliably — encoded in the observed signals. For example, a sufficiently resolved set of optical and microwave data may enable estimates of tree number, size, density, and condition or even species, but it often does not reveal how the land is being used — whether for forestry, agriculture, or recreation.

### 2.1.1. Optical EO satellites

Examples of optical multispectral sensors are plotted along with their bands in **Figure 2.1.1-1**. and some more along with their mission duration and spatial and temporal resolution satellites in **Figure 2.1.1-2**.  All these sensors are passive imagers. The more bands they have, the more subtle spectral signatures of different surfaces on the ground can be detected. Similar to human fingerprints, different ground surfaces interact with light and have their own unique signature. For example, vegetation and iron-rich surfaces have a unique signature in the very-near-infrared (VNIR), other surfaces such as clay minerals have a signature in the longer wavelengths, in the short-wave infrared (SWIR). 

![Spectral and spatial resolutions of common multispectral optical sensors][/figures/Figure2.1.1-1.png]  
**Figure 2.1.1-1**: Spectral and spatial resolutions of common multispectral optical sensors. Atmospheric windows are shown in grey. These are wavelengths thorough which light from the Sun cannot penetrate the Earth’s atmosphere. Spectral bands are shown in colored rectangles, and their numbers correspond to the band ID of their instrument. Source: [Cardoso-Fernandes et al. (2020)](https://www.mdpi.com/2076-3417/10/5/1785). 

![Years of operation, spatial resolution, and revisit period of optical satellite missions][/figures/Figure2.1.1-2.png]   
**Figure 2.1.1-2** : Years of operation, spatial resolution, and revisit period of optical satellite missions. The term ‘tasked’ refers to the fact that the satellite may return to the same place on Earth if it is requested by the satellite operators or the users. This means, the revisit is not guaranteed. Source: [Vos et al. (2019)](https://www.sciencedirect.com/science/article/abs/pii/S0378383918305313?via%3Dihub)

### 2.1.2. SAR

Synthetic Aperture Radar (SAR) sensors are active microwave imagers mostly operating in one single band. Their data is often  referred to as the **amplitude**, and the **phase** of the signal which is proportional to the time taken for the signal to return to the satellite. The SAR signal is sensitive to the structure of the object on the ground. The signal measured by the SAR sensor is called **backscatter**. Man-made structures such as buildings or ships in the sea act as strong reflectors \- returning more of the signal back to the satellite.  In contrast, other surfaces such as calm water causes most of the signal to randomly scatter away \- returning much less signal back to the satellite. Therefore, SAR is sensitive to the scattering mechanism of the object it interacts with. This property is enhanced by emitting and detecting the signal at different polarisations. For example, the development of agricultural crops (‘growth stages’) are tracked in this way and can help in prediction of yield. As crops grow, the dominant scattering mechanism may change so that vertically polarised signals may interact more with the vertical structures of the crops, such as stems and thus result in a higher signal return. In vegetated and rural areas, SAR backscatter is also highly dependent on the Vegetation Water Content (VWC), with higher backscatter returns for higher moisture content (**Figure 2.1.2-1**). To be noted, different wavelengths interact with different parts of the vegetation, with larger wavelengths, e.g. L-band, capturing the bottom part of the vegetation and potentially the soil level for low density forests, and smaller wavelengths, e.g. C-band, capturing the top of the canopy (**Figure 2.1.2-1**).     

![SAR signal interaction with vegetation][/figures/Figure2.1.2-1.png]  
**Figure 2.1.2-1**: SAR signal interaction with vegetation. Transmitted signal is shown in red and the returned signal is shown in blue. The returned signal strongly depends on the vegetation water content, with higher backscatter for higher moisture. Source: [Konings et al. (2021)](https://onlinelibrary.wiley.com/doi/10.1111/gcb.15872).

#### 2.1.1.1. InSAR

The interferogram between two SAR images contains information on the phase difference between the acquisitions and is referred to as **InSAR** (SAR **interferometry**). Whilst SAR data refers to the raw satellite data, InSAR refers to the processing chains of techniques used to estimate ground deformations and/or topographical height using the phase difference detected in SAR acquisitions. In satellite InSAR, successive acquisitions in time are obtained by the same satellite or a constellation of satellites with similar instrumental and orbital characteristics scanning the area of interest. Several processing schemes are feasible and interferometry is based on the production of interferograms, involving the use of the phase difference between acquisitions (i.e. at different times) to estimate the movement of the ground surface and its elevation.


[^3]: Content modified and adapted with permission from the [Satellite Applications Catapult Whitepaper by Kalaitzis et al. (2022) : State of AI for Earth Observation.](https://sa.catapult.org.uk/digital-library/white-paper-state-of-ai-for-earth-observation/)
