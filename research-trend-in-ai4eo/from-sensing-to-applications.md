[Previous](venues-of-cross-disciplinary-research.md) | [Table of contents](/README.md) | [Next](the-future-of-ai4eo-research.md)

***

## 3.2. From sensing to applications

**Table 3.2-1** provides a detailed breakdown of most of the work in AI4EO in various verticals. Here are the main takeaways:

* Most of the works in AI4EO investigate optical data since it is the most abundant.  
* **CNN** architectures have recently become the most ubiquitous architecture as they allow for the discovery of shift-invariant patterns not only in space, but also in time (**3D-CNNs**). They are also easier to train than **RNNs**, hence the latter are starting to be used less frequently. Therefore, CNNs are recognised as a natural fit for segmentation and classification problems in EO.  
* **SAR** data is becoming increasingly available, with many interesting use-cases emerging for InSAR.  
* With a heterogeneous array of sensors, it is clear that learning to **fuse** instruments harmoniously is key to complementing the observation gaps in isolated instruments.  
* The majority of use-cases in EO are framed as **segmentation** problems, to identify the spatial extent of an object, or regression / nowcasting / forecasting of continuous quantities, like crop yield.  
* Scientific fields have all found uses of ML to embed data into physical models (data assimilation), or fine-tuning physical models through data (parameter retrieval), or forming digital-twins of large-scale phenomena for cheaper simulation and at finer resolutions (down-scaling, subgrid-parametrization).  
* Agriculture is becoming the most frequent user of EO data (after intelligence / reconnaissance users), both in the environmental / sustainability front, like food-security, and commercially, for crop yield forecasting, monitoring, and asset management.  
* Understanding the type of some surface on the Earth (LULC) is a problem that cuts across many disciplines, and ties naturally with **classification** and **segmentation** ML tasks and **architectures**.

| proximity | sensor | method | task | application |
| ----- | ----- | ----: | ----- | ----: |
|  orbital / satellite \[[23](#bookmark=id.3tj0ee97c179), [24](#bookmark=id.888kfpnu51g9)\] aerial \[[25](#bookmark=id.1yi0827s6rvd),[26](#bookmark=id.cuco7sgdch61),[27](#bookmark=id.ilx6crnzu9dt), [28](#bookmark=id.rhk6bubn3p2z), [29](#bookmark=id.8gxp2akzoej3), [30](#bookmark=id.n9bjzrxt6ugr), [31](#bookmark=id.lwxis1uw16pw)\] in-situ / ground data \[[32](#bookmark=id.cjngr6rwv9gi), [33](#bookmark=id.non3dgauingy), [34](#bookmark=id.86ql0nh43b8j), [35](#bookmark=id.see9isotiw6q)\] |  optical \[[36](#bookmark=id.6y7mx0gnlbpe), [37](#bookmark=id.mptbc3l76wht), [38](#bookmark=id.49sspct8e5yu), [39](#bookmark=id.shrwmtww6ips), [40](#bookmark=id.ddvrcazeci56), [41](#bookmark=id.dqmil31y0zls), [42](#bookmark=id.tsb821ob3jqr), [43](#bookmark=id.7b3hwa5ne2tq), [44](#bookmark=id.bs91csxix09j), [45](#bookmark=id.qch2mmh7wyhy), [46](#bookmark=id.oj1l0me7zzrt), [47](#bookmark=id.o5y56ueohl6), [48](#bookmark=id.5dghccflh0rd), [49](#bookmark=id.2fi2o1ji1y9s), [50](#bookmark=id.quf5ti3wvvu7), [27](#bookmark=id.ilx6crnzu9dt), [51](#bookmark=id.khr4u4bqs011), [52](#bookmark=id.hrp5y99j844w), [53](#bookmark=id.3s9vfrixv2r0), [54](#bookmark=id.7cfdlasgttlo), [55](#bookmark=id.y02s67i1jeca), [56](#bookmark=id.dbquo1h6f97g), [57](#bookmark=id.e9g3ihv49a16), [58](#bookmark=id.6exh2rhirhqg), [59](#bookmark=id.olt2lp449goq), [60](#bookmark=id.rm6a436njvhx)\]  SAR \[[41](#bookmark=id.dqmil31y0zls), [25](#bookmark=id.1yi0827s6rvd), [61](#bookmark=id.pgcc14uzfhq6), [48](#bookmark=id.5dghccflh0rd), [62](#bookmark=id.jf60p8dquhe1), [63](#bookmark=id.mvitstd1nywz), [26](#bookmark=id.cuco7sgdch61), [34](#bookmark=id.86ql0nh43b8j), [64](#bookmark=id.712g324c8boc), [65](#bookmark=id.hhnv7lpxavkr), [66](#bookmark=id.a9cv4s409miw), [67](#bookmark=id.1bx98q7dt57l), [68](#bookmark=id.pxt4yos3evea), [69](#bookmark=id.cgeow0ubb3o5), [70](#bookmark=id.kna9cho95jop), [71](#bookmark=id.c1wmpj2c17ok), [72](#bookmark=id.xduryt5uo1sd), [60](#bookmark=id.rm6a436njvhx), [73](#bookmark=id.wqgr3bqok5yb), [74](#bookmark=id.eaf7j6eddfdp), [75](#bookmark=id.ghamhhv17id2)\] lidar \[[76](#bookmark=id.z3pertbdbsgl), [41](#bookmark=id.dqmil31y0zls), [26](#bookmark=id.cuco7sgdch61), [77](#bookmark=id.u4c9gxfiat8), [54](#bookmark=id.7cfdlasgttlo), [78](#bookmark=id.tboosoi94eq9), [79](#bookmark=id.4j6bzlc02a6d), [80](#bookmark=id.mvmgjnht23up), [29](#bookmark=id.8gxp2akzoej3), [30](#bookmark=id.n9bjzrxt6ugr), [31](#bookmark=id.lwxis1uw16pw), [81](#bookmark=id.zalc8prbq46t)\] | autoencoder \[[82](#bookmark=id.loxsgo6cba5u), [83](#bookmark=id.flgglmltdl76), [84](#bookmark=id.6gyq18bupsc8), [85](#bookmark=id.eodz2m3fr4g9)\]  attention / transformer \[[86](#bookmark=id.k67v5ikstcua), [68](#bookmark=id.pxt4yos3evea), [52](#bookmark=id.hrp5y99j844w), [81](#bookmark=id.zalc8prbq46t), [87](#bookmark=id.q89m11ui0gxd)\]  Bayesian / probabilistic \[[32](#bookmark=id.cjngr6rwv9gi), [33](#bookmark=id.non3dgauingy), [88](#bookmark=id.pdubf4xctjrg)\] CNN / U-Net / ResNet \[[39](#bookmark=id.shrwmtww6ips), [76](#bookmark=id.z3pertbdbsgl), [40](#bookmark=id.ddvrcazeci56), [42](#bookmark=id.tsb821ob3jqr), [45](#bookmark=id.qch2mmh7wyhy), [62](#bookmark=id.jf60p8dquhe1), [50](#bookmark=id.quf5ti3wvvu7), [89](#bookmark=id.xi8btkv8rw90), [90](#bookmark=id.7nar0twfndbn), [65](#bookmark=id.hhnv7lpxavkr), [68](#bookmark=id.pxt4yos3evea), [52](#bookmark=id.hrp5y99j844w), [91](#bookmark=id.368wylvq94p8), [77](#bookmark=id.u4c9gxfiat8), [28](#bookmark=id.rhk6bubn3p2z), [92](#bookmark=id.tiq9lvfu3354), [54](#bookmark=id.7cfdlasgttlo), [59](#bookmark=id.olt2lp449goq), [81](#bookmark=id.zalc8prbq46t)\]  ensemble \[[33](#bookmark=id.non3dgauingy), [42](#bookmark=id.tsb821ob3jqr)\]  GAN \[[62](#bookmark=id.jf60p8dquhe1), [93](#bookmark=id.22j2liyb6nu4), [94](#bookmark=id.i7go6k3l77nz), [95](#bookmark=id.5m0zletyls8m)\]  boosting \[[48](#bookmark=id.5dghccflh0rd)\]  regression \[[25](#bookmark=id.1yi0827s6rvd), [96](#bookmark=id.272vwlnxg3hm), [82](#bookmark=id.loxsgo6cba5u), [43](#bookmark=id.7b3hwa5ne2tq), [48](#bookmark=id.5dghccflh0rd), [62](#bookmark=id.jf60p8dquhe1), [97](#bookmark=id.7h2viu5yocxk), [98](#bookmark=id.vlo47lyl7njq)\]  MLP \[[99](#bookmark=id.lcqwvcvqfy82), [42](#bookmark=id.tsb821ob3jqr), [100](#bookmark=id.2t4pcalfuc4e)\]  random forest \[[61](#bookmark=id.pgcc14uzfhq6), [45](#bookmark=id.qch2mmh7wyhy), [48](#bookmark=id.5dghccflh0rd), [97](#bookmark=id.7h2viu5yocxk)\]  RNN \[[32](#bookmark=id.cjngr6rwv9gi), [61](#bookmark=id.pgcc14uzfhq6), [47](#bookmark=id.o5y56ueohl6), [88](#bookmark=id.pdubf4xctjrg), [50](#bookmark=id.quf5ti3wvvu7), [66](#bookmark=id.a9cv4s409miw), [92](#bookmark=id.tiq9lvfu3354), [60](#bookmark=id.rm6a436njvhx)\]  SVM \[[61](#bookmark=id.pgcc14uzfhq6), [48](#bookmark=id.5dghccflh0rd), [62](#bookmark=id.jf60p8dquhe1), [101](#bookmark=id.rukh9u594dv3)\] | anomaly detection \[[102](#bookmark=id.36r4bcxdzuqh), [85](#bookmark=id.eodz2m3fr4g9)\]  change detection \[[41](#bookmark=id.dqmil31y0zls), [103](#bookmark=id.navzbsllsn0d), [62](#bookmark=id.jf60p8dquhe1), [69](#bookmark=id.cgeow0ubb3o5), [71](#bookmark=id.c1wmpj2c17ok), [104](#bookmark=id.gy4i9yhi4z98), [105](#bookmark=id.8eqr0dj4pywn)\]  classification \[[36](#bookmark=id.6y7mx0gnlbpe), [40](#bookmark=id.ddvrcazeci56), [42](#bookmark=id.tsb821ob3jqr), [82](#bookmark=id.loxsgo6cba5u), [106](#bookmark=id.r4yxvr8051od), [103](#bookmark=id.navzbsllsn0d), [44](#bookmark=id.bs91csxix09j), [45](#bookmark=id.qch2mmh7wyhy), [47](#bookmark=id.o5y56ueohl6), [27](#bookmark=id.ilx6crnzu9dt), [65](#bookmark=id.hhnv7lpxavkr), [52](#bookmark=id.hrp5y99j844w), [91](#bookmark=id.368wylvq94p8), [77](#bookmark=id.u4c9gxfiat8), [75](#bookmark=id.ghamhhv17id2)\]  data assimilation \[[96](#bookmark=id.272vwlnxg3hm), [82](#bookmark=id.loxsgo6cba5u), [88](#bookmark=id.pdubf4xctjrg), [107](#bookmark=id.fxlznwpvch8s), [108](#bookmark=id.mxmkl3c90xbp)\]  enhancement / infilling / image translation \[[103](#bookmark=id.navzbsllsn0d), [66](#bookmark=id.a9cv4s409miw), [109](#bookmark=id.qe808onfmmso), [110](#bookmark=id.chdk6stah641), [57](#bookmark=id.e9g3ihv49a16), [93](#bookmark=id.22j2liyb6nu4), [94](#bookmark=id.i7go6k3l77nz), [98](#bookmark=id.vlo47lyl7njq), [95](#bookmark=id.5m0zletyls8m)\]  object detection \[[39](#bookmark=id.shrwmtww6ips), [106](#bookmark=id.r4yxvr8051od), [103](#bookmark=id.navzbsllsn0d), [50](#bookmark=id.quf5ti3wvvu7), [101](#bookmark=id.rukh9u594dv3)\]  registration / image matching \[[111](#bookmark=id.ayi2r4cfons6), [112](#bookmark=id.2elsyncvizn6)\]  regression / forecasting \[[99](#bookmark=id.lcqwvcvqfy82), [25](#bookmark=id.1yi0827s6rvd), [82](#bookmark=id.loxsgo6cba5u), [43](#bookmark=id.7b3hwa5ne2tq), [48](#bookmark=id.5dghccflh0rd), [107](#bookmark=id.fxlznwpvch8s), [49](#bookmark=id.2fi2o1ji1y9s), [64](#bookmark=id.712g324c8boc), [100](#bookmark=id.2t4pcalfuc4e), [92](#bookmark=id.tiq9lvfu3354), [113](#bookmark=id.ulldxyb51j3j), [97](#bookmark=id.7h2viu5yocxk), [35](#bookmark=id.see9isotiw6q), [74](#bookmark=id.eaf7j6eddfdp)\]  search / mining \[[36](#bookmark=id.6y7mx0gnlbpe), [103](#bookmark=id.navzbsllsn0d), [114](#bookmark=id.2iialeei0h7m), [107](#bookmark=id.fxlznwpvch8s), [108](#bookmark=id.mxmkl3c90xbp), [115](#bookmark=id.igx564q7cjwr), [87](#bookmark=id.q89m11ui0gxd)\]  segmentation \[[36](#bookmark=id.6y7mx0gnlbpe), [37](#bookmark=id.mptbc3l76wht), [39](#bookmark=id.shrwmtww6ips), [76](#bookmark=id.z3pertbdbsgl), [40](#bookmark=id.ddvrcazeci56), [42](#bookmark=id.tsb821ob3jqr), [82](#bookmark=id.loxsgo6cba5u), [44](#bookmark=id.bs91csxix09j), [116](#bookmark=id.ta2a1txe2t1q), [50](#bookmark=id.quf5ti3wvvu7), [90](#bookmark=id.7nar0twfndbn), [117](#bookmark=id.2qf6jtax10ah), [57](#bookmark=id.e9g3ihv49a16), [60](#bookmark=id.rm6a436njvhx)\]  sensor fusion \[[41](#bookmark=id.dqmil31y0zls), [42](#bookmark=id.tsb821ob3jqr), [82](#bookmark=id.loxsgo6cba5u), [103](#bookmark=id.navzbsllsn0d), [88](#bookmark=id.pdubf4xctjrg), [26](#bookmark=id.cuco7sgdch61), [108](#bookmark=id.mxmkl3c90xbp), [52](#bookmark=id.hrp5y99j844w), [113](#bookmark=id.ulldxyb51j3j), [80](#bookmark=id.mvmgjnht23up), [81](#bookmark=id.zalc8prbq46t), [*118*](#bookmark=id.p8hl8sowjntv)\]  surrogate modelling \[[99](#bookmark=id.lcqwvcvqfy82), [96](#bookmark=id.272vwlnxg3hm), [108](#bookmark=id.mxmkl3c90xbp), [35](#bookmark=id.see9isotiw6q)\]  transfer learning \[[82](#bookmark=id.loxsgo6cba5u), [43](#bookmark=id.7b3hwa5ne2tq), [50](#bookmark=id.quf5ti3wvvu7), [91](#bookmark=id.368wylvq94p8)\]  unsupervised learning \[[115](#bookmark=id.igx564q7cjwr), [53](#bookmark=id.3s9vfrixv2r0), [59](#bookmark=id.olt2lp449goq)\] | agriculture \[[25](#bookmark=id.1yi0827s6rvd), [42](#bookmark=id.tsb821ob3jqr), [119](#bookmark=id.3uhat8bwjoy3), [120](#bookmark=id.x25dxg1xlxo4), [82](#bookmark=id.loxsgo6cba5u), [43](#bookmark=id.7b3hwa5ne2tq), [46](#bookmark=id.oj1l0me7zzrt), [63](#bookmark=id.mvitstd1nywz), [121](#bookmark=id.53u0ndohl3ql), [100](#bookmark=id.2t4pcalfuc4e), [52](#bookmark=id.hrp5y99j844w), [113](#bookmark=id.ulldxyb51j3j), [97](#bookmark=id.7h2viu5yocxk), [29](#bookmark=id.8gxp2akzoej3), [30](#bookmark=id.n9bjzrxt6ugr)\]  climate  \[[99](#bookmark=id.lcqwvcvqfy82), [122](#bookmark=id.op9saobrildo), [88](#bookmark=id.pdubf4xctjrg), [48](#bookmark=id.5dghccflh0rd), [63](#bookmark=id.mvitstd1nywz), [49](#bookmark=id.2fi2o1ji1y9s), [53](#bookmark=id.3s9vfrixv2r0), [92](#bookmark=id.tiq9lvfu3354)\]  earth / geo science \[[99](#bookmark=id.lcqwvcvqfy82), [96](#bookmark=id.272vwlnxg3hm), [82](#bookmark=id.loxsgo6cba5u), [88](#bookmark=id.pdubf4xctjrg), [63](#bookmark=id.mvitstd1nywz), [107](#bookmark=id.fxlznwpvch8s), [123](#bookmark=id.rs6iyhu0fxoq), [108](#bookmark=id.mxmkl3c90xbp), [31](#bookmark=id.lwxis1uw16pw)\]  energy \[[36](#bookmark=id.6y7mx0gnlbpe), [33](#bookmark=id.non3dgauingy), [82](#bookmark=id.loxsgo6cba5u), [74](#bookmark=id.eaf7j6eddfdp)\]  environmental science \[[82](#bookmark=id.loxsgo6cba5u), [61](#bookmark=id.pgcc14uzfhq6), [34](#bookmark=id.86ql0nh43b8j)\]  epidemiology \[[51](#bookmark=id.khr4u4bqs011)\]  finance / insurance \[[58](#bookmark=id.6exh2rhirhqg), [124](#bookmark=id.vskcjn3bydn8)\]  ship / aircraft awareness \[[39](#bookmark=id.shrwmtww6ips), [65](#bookmark=id.hhnv7lpxavkr), [73](#bookmark=id.wqgr3bqok5yb), [75](#bookmark=id.ghamhhv17id2)\] geology  \[[86](#bookmark=id.k67v5ikstcua), [119](#bookmark=id.3uhat8bwjoy3), [63](#bookmark=id.mvitstd1nywz), [69](#bookmark=id.cgeow0ubb3o5), [71](#bookmark=id.c1wmpj2c17ok), [54](#bookmark=id.7cfdlasgttlo), [56](#bookmark=id.dbquo1h6f97g)\]  hydrology / hydrography \[[32](#bookmark=id.cjngr6rwv9gi), [38](#bookmark=id.49sspct8e5yu), [82](#bookmark=id.loxsgo6cba5u), [46](#bookmark=id.oj1l0me7zzrt), [64](#bookmark=id.712g324c8boc), [54](#bookmark=id.7cfdlasgttlo)\]  infrastructure / development \[[36](#bookmark=id.6y7mx0gnlbpe), [37](#bookmark=id.mptbc3l76wht), [40](#bookmark=id.ddvrcazeci56), [49](#bookmark=id.2fi2o1ji1y9s), [102](#bookmark=id.36r4bcxdzuqh), [69](#bookmark=id.cgeow0ubb3o5), [70](#bookmark=id.kna9cho95jop)\]  LULC / forestry \[[42](#bookmark=id.tsb821ob3jqr), [82](#bookmark=id.loxsgo6cba5u), [106](#bookmark=id.r4yxvr8051od), [103](#bookmark=id.navzbsllsn0d), [61](#bookmark=id.pgcc14uzfhq6), [47](#bookmark=id.o5y56ueohl6), [62](#bookmark=id.jf60p8dquhe1), [27](#bookmark=id.ilx6crnzu9dt)\]  livestock \[[125](#bookmark=id.o3z9k4so86xw)\]  maritime \[[45](#bookmark=id.qch2mmh7wyhy), [65](#bookmark=id.hhnv7lpxavkr), [55](#bookmark=id.y02s67i1jeca), [75](#bookmark=id.ghamhhv17id2)\] |

**Table 3.2-1**: From sensing to application. A breakdown of work in AI4EO in terms of the type of sensor employed, modelling approach, prediction task, and application domain.

|  **task** | attention / transformer | CNN | RNN | GAN | MLP | random forest | regression | SVM | Bayesian / probabilistic |
| ----- | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: |
| **change detection** anomaly**,** LULC |  | \[[82](#bookmark=id.loxsgo6cba5u), [62](#bookmark=id.jf60p8dquhe1),[85](#bookmark=id.eodz2m3fr4g9)\] |  |  |  |  | \[[62](#bookmark=id.jf60p8dquhe1)\] | \[[62](#bookmark=id.jf60p8dquhe1)\]  |  |
| **classification** building, damage, vehicle, hazard, scene, LULC, crop | \[[52](#bookmark=id.hrp5y99j844w), [81](#bookmark=id.zalc8prbq46t)\] | \[[40](#bookmark=id.ddvrcazeci56), [42](#bookmark=id.tsb821ob3jqr), [82](#bookmark=id.loxsgo6cba5u), [45](#bookmark=id.qch2mmh7wyhy), [62](#bookmark=id.jf60p8dquhe1), [65](#bookmark=id.hhnv7lpxavkr), [52](#bookmark=id.hrp5y99j844w), [91](#bookmark=id.368wylvq94p8), [77](#bookmark=id.u4c9gxfiat8), [28](#bookmark=id.rhk6bubn3p2z)\] | \[[61](#bookmark=id.pgcc14uzfhq6), [47](#bookmark=id.o5y56ueohl6)\] |  | \[[42](#bookmark=id.tsb821ob3jqr)\] | \[[61](#bookmark=id.pgcc14uzfhq6), [45](#bookmark=id.qch2mmh7wyhy)\] | \[[82](#bookmark=id.loxsgo6cba5u)\] | \[[61](#bookmark=id.pgcc14uzfhq6)\] |  |
| **search / mining** question answering**,** relational reasoning**,** image search | \[[87](#bookmark=id.q89m11ui0gxd)\]   |  |  |  |  |  |  |  |  |
| **Image translation** inpainting, infilling**,** super-resolution, pansharpening, deblurring, denoising, synthetic generation | \[[68](#bookmark=id.pxt4yos3evea)\] | \[[68](#bookmark=id.pxt4yos3evea)\] | \[[66](#bookmark=id.a9cv4s409miw)\] | \[[93](#bookmark=id.22j2liyb6nu4), [94](#bookmark=id.i7go6k3l77nz), [95](#bookmark=id.5m0zletyls8m)\] |  |  | \[[98](#bookmark=id.vlo47lyl7njq)\] |  |  |
| **fusion** cross-calibration, harmonisation, optical \+ optical, optical \+ lidar**,**  optical \+ SAR | \[[52](#bookmark=id.hrp5y99j844w), [81](#bookmark=id.zalc8prbq46t)\] | \[[42](#bookmark=id.tsb821ob3jqr), [48](#bookmark=id.5dghccflh0rd), [52](#bookmark=id.hrp5y99j844w), [77](#bookmark=id.u4c9gxfiat8), [54](#bookmark=id.7cfdlasgttlo), [81](#bookmark=id.zalc8prbq46t), [118](#bookmark=id.p8hl8sowjntv),\] | \[[32](#bookmark=id.cjngr6rwv9gi), [88](#bookmark=id.pdubf4xctjrg)\] |  | \[[42](#bookmark=id.tsb821ob3jqr)\] |   |  |  | \[[32](#bookmark=id.cjngr6rwv9gi)\] |
| **object detection / counting** Infrastructure, vehicle, cattle |  | \[[50](#bookmark=id.quf5ti3wvvu7), [89](#bookmark=id.xi8btkv8rw90)\] | \[[50](#bookmark=id.quf5ti3wvvu7)\] |  |  |  |  | \[[101](#bookmark=id.rukh9u594dv3)\] |  |
| **registration /  image matching** video stabilisation, 3D reconstruction, orthorectification |  | \[[111](#bookmark=id.ayi2r4cfons6), [112](#bookmark=id.2elsyncvizn6)\] |  |  |  |  | \[[111](#bookmark=id.ayi2r4cfons6), [112](#bookmark=id.2elsyncvizn6)\] |  |  |
| **regression / forecasting** water volume**,** precipitation**,** temperature**,** velocimetry, utilisation, biomass, moisture, wind power |  |  | \[[32](#bookmark=id.cjngr6rwv9gi), [82](#bookmark=id.loxsgo6cba5u)\] |  | \[[99](#bookmark=id.lcqwvcvqfy82), [100](#bookmark=id.2t4pcalfuc4e)\] | \[[48](#bookmark=id.5dghccflh0rd), [97](#bookmark=id.7h2viu5yocxk)\] | \[[25](#bookmark=id.1yi0827s6rvd), [43](#bookmark=id.7b3hwa5ne2tq), [48](#bookmark=id.5dghccflh0rd), [82](#bookmark=id.loxsgo6cba5u)\] | \[[48](#bookmark=id.5dghccflh0rd), [97](#bookmark=id.7h2viu5yocxk)\] | \[[32](#bookmark=id.cjngr6rwv9gi), [33](#bookmark=id.non3dgauingy)\] |
| **segmentation** cloud / shadow, vegetation, building, oil slick, LULC, water, rock, road, crop | \[[86](#bookmark=id.k67v5ikstcua) | \[[39](#bookmark=id.shrwmtww6ips), [76](#bookmark=id.z3pertbdbsgl), [40](#bookmark=id.ddvrcazeci56), [42](#bookmark=id.tsb821ob3jqr), [82](#bookmark=id.loxsgo6cba5u), [50](#bookmark=id.quf5ti3wvvu7), [89](#bookmark=id.xi8btkv8rw90), [90](#bookmark=id.7nar0twfndbn), [54](#bookmark=id.7cfdlasgttlo) | \[[50](#bookmark=id.quf5ti3wvvu7), [60](#bookmark=id.rm6a436njvhx)\] |  | \[[42](#bookmark=id.tsb821ob3jqr)\] |  | \[[82](#bookmark=id.loxsgo6cba5u)\] |  |  |
| **transfer learning** self-supervised, semi-supervised, zero/few-shot learning, domain adaptation |  | \[[91](#bookmark=id.368wylvq94p8), [59](#bookmark=id.olt2lp449goq) | \[[50](#bookmark=id.quf5ti3wvvu7)\] |  |  |  |  |  |  |

**Table 3.2-2**: Tasks and models. Selected works in AI4EO grouped by task and modelling approach. 



***

[Previous](venues-of-cross-disciplinary-research.md) | [Table of contents](/README.md) | [Next](the-future-of-ai4eo-research.md)
