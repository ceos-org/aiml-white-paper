[Previous](research-trends-in-ai4eo.md) | [Table of contents](/README.md) | [Next](from-sensing-to-applications.md)

***

## 3.1. Venues of cross-disciplinary research

The following is a brief overview on top-tier academic conferences, for the readers who are interested in staying up to date with the SOTA in ML. Key journal publications include: JMLR\[[2](/reference.md#ref.2)\], TPAMI \[[3](/reference.md#ref.3)\], FTML\[[4](/reference.md#ref.4)\], TMLR\[[5](/reference.md#ref.5)\]. Key conferences include: NeurIPS \[[6](/reference.md#ref.6)\], ICML, ICLR\[[7](/reference.md#ref.7)\], CVPR\[[8](/reference.md#ref.8)\], AAAI\[[9](/reference.md#ref.9)\], AISTATS\[[10](/reference.md#ref.10)\]. Aside from the main proceedings, each conference also hosts satellite academic workshop events catered to researchers working in specific basic and applied research domains. In the context of AI4EO, the following AI4EO workshops are staples in most annual iterations of the aforementioned conferences: EarthVision\[[11](/reference.md#ref.11)\], AI4Earth\[[12](/reference.md#ref.12)\], MLPS\[[13](/reference.md#ref.13)\], CCAI\[[14](/reference.md#ref.14)\]. Because of their interdisciplinary nature, some of these events are supported by IEEE technical committees which also host their own conferences, like IGARSS\[[15](/reference.md#ref.15)\].

The development and publication of ideas in AI4EO follow a common trajectory:

1. A new SOTA is published at a conference, typically on a problem unrelated to EO.  
2. EO practitioners discover the new ML paper and translate it to their problem.  
3. Occasionally, the translation of the new paper will be successful and the EO researchers will publish their preliminary results in a EO workshop or symposium, such as AGU\[[16](/reference.md#ref.16)\], EGU\[[17](/reference.md#ref.17)\], LPS\[[18](/reference.md#ref.18)\]. This is a good opportunity to receive early feedback from the EO research community.  
4. Finally, the new ML application makes it into a EO or RS journal.

Note that at step 1 of this workflow the new ML methods are not benchmarked on EO datasets. This status quo is perpetuated by much of the ML community framing the advancement of the **SOTA** only with respect to traditional benchmarks for image classification, segmentation, object detection—like ImageNet \[[19](/reference.md#ref.19)\], CIFAR\[[20](/reference.md#ref.20)\], COCO \[[21](/reference.md#ref.21)\]—while EO tasks are not yet featured in the standard regiment of benchmarks. However, an increasing number of larger and larger scale datasets are starting to pop up, like those of the SpaceNet competitions\[[22](/reference.md#ref.22)\]. 

[Previous](research-trends-in-ai4eo.md) | [Table of contents](/README.md) | [Next](from-sensing-to-applications.md)

***
